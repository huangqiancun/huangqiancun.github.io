<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/icons8-fox-32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/icons8-fox-16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,">





  <link rel="alternate" href="/atom.xml" title="I'm Qiancun Huang" type="application/atom+xml">






<meta name="description" content="本文主要是机器学习-特征工程相关内容。 1 什么是特征工程对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限。 特征工程是指对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-特征工程">
<meta property="og:url" content="http://huangqiancun.github.io/2019/06/20/机器学习-特征工程/index.html">
<meta property="og:site_name" content="I&#39;m Qiancun Huang">
<meta property="og:description" content="本文主要是机器学习-特征工程相关内容。 1 什么是特征工程对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限。 特征工程是指对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-07-26T15:03:16.224Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习-特征工程">
<meta name="twitter:description" content="本文主要是机器学习-特征工程相关内容。 1 什么是特征工程对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限。 特征工程是指对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://huangqiancun.github.io/2019/06/20/机器学习-特征工程/">





  <title>机器学习-特征工程 | I'm Qiancun Huang</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">I'm Qiancun Huang</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Live it. Love it. Enjoy IT.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://huangqiancun.github.io/2019/06/20/机器学习-特征工程/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Qiancun Huang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/photo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="I'm Qiancun Huang">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">机器学习-特征工程</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-20T09:02:25+08:00">
                2019-06-20
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">Post modified&#58;</span>
              
              <time title="Post modified" itemprop="dateModified" datetime="2019-07-26T23:03:16+08:00">
                2019-07-26
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  8.5k
                </span>
              

              

              
            </div>
          

          
		  

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文主要是<code>机器学习-特征工程</code>相关内容。</p>
<h2 id="1-什么是特征工程"><a href="#1-什么是特征工程" class="headerlink" title="1 什么是特征工程"></a>1 什么是特征工程</h2><p>对于一个机器学习问题，数据和特征往往决定了结果的上限，而模型、算法的选择及优化则是在逐步接近这个上限。 特征工程是指对原始数据进行一系列工程处理，将其提炼为特征，作为输入供算法和模型使用。从本质上来讲，特征工程是一个表示和展现数据的过程。在实际工作中，特征工程旨在去除原始数据中的杂质和冗余，设计更高效的特征以刻画求解的问题与预测模型之间的关系。特征工程主要包括数据与特征处理，特征选择和降维三部分内容。</p>
<p>对数据进行预处理，可提高数据质量，提高挖掘质量。对数据进行清洗可填充缺失值，光滑噪声数据，识别和删除离群点数据，保证数据的一致性。使用正确的采样方法可解决因数据不平衡带来的预测偏差。 对不同的数据类型进行不同的特征处理有助于提高特征的可用性。例如：</p>
<ul>
<li>对数值型数据进行归一化可将数据转化到同一量纲下；</li>
<li>对类别性数据，可以使用one-hot编码方法将类别数据数字化，数字化特征之后可用来计算距离，相似性等；</li>
<li>可从时间型数据中提取更多的时间特征，如年月日等，这些特征对于业务场景以及模型的预测往往有很大的帮助，统计性特征处理有助于从业务场景中挖掘更丰富的信息。</li>
</ul>
<h2 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2 数据预处理"></a>2 数据预处理</h2><p>数据预处理：无量纲化（标准化，区间缩放法，标准化与归一化的区别），对定量标准二值化，对定性特征哑编码，缺失值计算，数据变换。步骤如下:</p>
<ul>
<li>将数据导入</li>
<li>看数据。重点看元数据，即对字段解释，数据来源等信息，导入数据后，提取部分数据进行查看</li>
<li>缺失值清洗。根据需要对缺失值进行处理，可以删除数据或填充数据。重新取数：如果某些非常重要的字段缺失，需要和负责采集数据的人沟通，是否可以再次获得。</li>
<li>数据格式清洗：统一数据的时间，日期，全半角等显示格式</li>
<li>逻辑错误的数据：重复的数据，不合理的值</li>
<li>不一致错误的处理：指对矛盾内容的修正，最常见的如身份证号和出生年月日不对应。</li>
</ul>
<h2 id="3-处理类别型特征"><a href="#3-处理类别型特征" class="headerlink" title="3 处理类别型特征"></a>3 处理类别型特征</h2><ul>
<li>序号编码，序号编码通常用于处理类别间具有大小关系的数据，例如成绩，可以分为低、中、高三档，并且存在“高&gt;中&gt;低”的排序关系。序号编码会按照大小关系对类别型特征赋予一个数值ID，例如高表示为3、中表示为2、低表示为1，转换后依然保留了大小关系。</li>
<li>独热编码，独热编码通常用于处理类别间不具有大小关系的特征。例如血型，一共有4个取值（A型血、B型血、AB型血、O型血），独热编码会把血型变成一个4维稀疏向量，A型血表示为（1,0,0,0），B型血表示为（0,1,0,0），AB型表示为（0,0,1,0），O型血表示为（0,0,0,1）。</li>
<li>二进制编码，二进制编码主要分为两步，先用序号编码给每个类别赋予一个类别ID，然后将类别ID对应的二进制编码作为结果。以A、B、AB、O血型为例。A型血的ID为1，二进制表示为001；B型血的ID为2，二进制表示为010；以此类推可以得到AB型血和O型血的二进制表示。可以看出，二进制编码本质上是利用二进制对ID进行哈希映射，最终得到0/1特征向量，且维数少于独热编码，节省了存储空间。</li>
</ul>
<h2 id="4-特征选择的方法"><a href="#4-特征选择的方法" class="headerlink" title="4 特征选择的方法"></a>4 特征选择的方法</h2><p>filter（过滤式）：过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关。这相当于先用特征选择过程对初始特征进行”过滤”，再用过滤后的特征来训练模型。</p>
<ul>
<li>Relief(Relevant Features)是一种著名的过滤式特征选择方法，该方法设计了一个”相关统计量”来度量特征的重要性。该统计量是一个向量，其每个分量分别对应于一个初始特征，而特征子集的重要性则是由子集中每个特征所对应的相关统计量分量之和来决定。于是，最终只需指定一个阈值T，然后选择比T大的相关统计量分量所对应的特征即可；也可指定欲选取的特征个数k，然后选择相关统计量分量最大的k个特征。</li>
</ul>
<p>wrapper（包裹式）：与过滤式特征选择不考虑后续学习器不同，包裹式特征选择直接把最终将要使用的学习器的性能作为特征子集的评价准则。换言之，包裹式特征选择的目的就是为给定学习器选择最有利于其性能、”量身定做”的特征子集。</p>
<ul>
<li>一般而言，由于包裹式特征选择方法直接针对给定学习器进行优化，因此从最终学习器性能来看，包裹式特征选择比过滤式特征选择更好，但另一方面，由于在特征选择过程中需多次训练学习器，因此包裹式特征选择的计算开销通常比过滤式特征边择大得多。</li>
</ul>
<p>embedded（嵌入法）：基于惩罚项的特征选择法。</p>
<ul>
<li>在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明显的分别；与此不同，嵌入式特征选择是将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动地进行了特征选择。常见的有LASSO回归。</li>
</ul>
<h2 id="5-如何进行特征选择"><a href="#5-如何进行特征选择" class="headerlink" title="5 如何进行特征选择"></a>5 如何进行特征选择</h2><p>特征选择是一个重要的数据预处理过程，主要有两个目的：一是减少特征数量，降维，使模型泛化能力更强，减少过拟合；二是增强对特征和特征值之前的理解。常见的特征选择方法：</p>
<ul>
<li>去除方差较小的特征；</li>
<li>单变量特征选择，对每一个特征进行测试，衡量该特征和输出响应之间的关系，根据得分去掉不好的特征；</li>
<li>使用正则化。L1正则化能够使模型变得稀疏。L2正则化的表现更加稳定，由于有用的特征对应系数非零。</li>
<li>随机森林<ul>
<li>平均不纯度减少mean decrease impurity：利用不纯度确定节点分裂特征，对于分类问题，通常采用基尼系数或者信息增益，对于回归问题，通常采用方差或者最小二乘拟合，当训练决策树的时候，可以计算出每个特征减少了多少不纯度，并把它减少的不纯度作为特征选择的值。</li>
<li>平均精确率减少Mean decrease accuracy：直接度量每个特征对模型精确率的影响，主要思路是分别打乱每个特征的特征值排序，并且度量顺序变动对模型的精确率的影响。很明显，对于不重要的变量来说，打乱顺序对模型的精确率影响不会太大，但是对于重要的顺序，打乱顺序就会降低模型的精确率</li>
</ul>
</li>
<li>稳定性选择Stability selection。稳定性选择是一种二次抽样和特征选择算法相结合的较新的方法，选择算法可以是回归，SVM或其他类似的方法。它的主要思想是在不同的数据子集和特征子集上运行特征选择算法，不断的重复，最终汇总特征选择结果，比如可以统计某个特征被认为是重要特征的频率（被选为重要特征的次数除以它所在的子集被测试的次数）。理想情况下，重要特征的得分会接近100%。稍微弱一点的特征得分会是非0的数，而最无用的特征得分将会接近于0。</li>
<li>递归特征消除Recursive feature elimination(RFE)。递归特征消除的主要思想是反复地构建模型，然后选出最好的特征（可以根据系数来选），把选出来的特征放在一边，然后在剩余的特征上重复这个过程，直到所有特征都遍历了。这个过程中特征被消除的次序就是特征的排序。因此这是一种寻找最优特征子集的贪心算法。</li>
</ul>
<h2 id="6-组合特征"><a href="#6-组合特征" class="headerlink" title="6 组合特征"></a>6 组合特征</h2><p>为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。两个特征的取值数量分别为m和n，那么组合之后的规模为m×n。</p>
<h2 id="7-有效地寻找组合特征"><a href="#7-有效地寻找组合特征" class="headerlink" title="7 有效地寻找组合特征"></a>7 有效地寻找组合特征</h2><p>如果简单地两两组合，依然容易存在参数过多、过拟合等问题，而且并不是所有的特征组合都是有意义的，可以使用基于决策树的特征组合寻找方法，每一条从根节点到叶节点的路径都可以看成一种特征组合的方式。</p>
<h2 id="8-标准化和归一化的区别"><a href="#8-标准化和归一化的区别" class="headerlink" title="8 标准化和归一化的区别"></a>8 标准化和归一化的区别</h2><p>标准化：将数据按比例缩放，使每个特征的均值变为0，标准差变为1.目的是使得不同度量之间的特征具有可比性的同时不改变原始分布，对目标函数的影响体现在几何分布上。$X^{\prime}=(x-u) / \sigma$。</p>
<p>归一化：将有量纲的表达式变成无量纲的表达式，便于不同单位或量级的指标能够进行比较和加权，一般是将数据变成(0,1)或者(1,1)之间的小数，归一化会改变原始数据的分布，使各个特征维度对目标函数的影响权重是一致的，也就是使那些扁平分布的数据伸缩变换成类圆形分布，对目标函数的影响体现在数值上。$X^{\prime}=(x-x_{min} ) /(x_{max} -x_{min} )$。</p>
<p>一个椭圆形分布的数据，如果采用标准化，不会改变两个维度上的分布，还是会保持椭圆形。而采用归一化则会在不同维度上对数据进行不同的伸缩变换，会改变数据的原始距离及分布信息，使其呈类圆形。</p>
<p>虽然归一化会丢掉数据的原始信息，但这防止了直接对原始数据进行梯度下降的优化算法时最终被数值大的特征所主导，归一化之后，各个特征对目标函数的影响权重是一致的，可以提升模型的收敛速度和提高模型的精度。</p>
<h2 id="9-归一化的作用"><a href="#9-归一化的作用" class="headerlink" title="9 归一化的作用"></a>9 归一化的作用</h2><p>归一化加快了梯度下降求最优解的速度，归一化有可能提高精度。</p>
<ul>
<li>提升收敛速度：在特征量纲不一样时，可能一个特征的数值远大于另一个特征，在用原始数据进行优化时，会得到一个窄长的椭圆形，导致在梯度下降时，梯度的方向为垂直等高线的方向而走之字形路线，这样会使迭代很慢，相比之下，归一化的迭代就会很快，即步长走多走少方向总是对的，不会走偏。</li>
<li>提升模型的精度：比如算法要计算欧氏距离，当各特征之间的水平相差很大时，如果直接使用原始数据进行分析，就会突出数值较大的特征在计算时的作用，相对削弱数值较小的特征的作用，而实际上我们可能认为两个维度对结果同样重要，所以不进行归一化会造成精度的损失，这在距离计算的算法中影响较大。</li>
</ul>
<h2 id="10-不需要做归一化的机器学习算法"><a href="#10-不需要做归一化的机器学习算法" class="headerlink" title="10 不需要做归一化的机器学习算法"></a>10 不需要做归一化的机器学习算法</h2><p>在实际应用中，通过梯度下降法求解的模型一般都是需要归一化的，如线性回归，逻辑斯蒂回归，KNN，SVM，神经网络等模型。但树模型不需要归一化，因为树模型不关心特征的值，而是只关心特征的分布和特征之间的条件概率，如决策树，随机森林等。</p>
<h2 id="11-文本表示模型"><a href="#11-文本表示模型" class="headerlink" title="11 文本表示模型"></a>11 文本表示模型</h2><ul>
<li>词袋模型和N-gram模型</li>
</ul>
<p>最基础的文本表示模型是词袋模型。顾名思义，就是将每篇文章看成一袋子词，并忽略每个词出现的顺序。具体地说，就是将整段文本以词为单位切分开，然后每篇文章可以表示成一个长向量，向量中的每一维代表一个单词，而该维对应的权重则反映了这个词在原文章中的重要程度。常用TF-IDF来计算权重，公式为</p>
<script type="math/tex; mode=display">
\mathrm{TF}-\mathrm{IDF}(t, d)=\mathrm{TF}(t, d) \times \operatorname{IDF}(t)</script><p>其中 $\mathrm{TF}(t, d)$ 为单词 t 在文档 d 中出现的频率，$\operatorname{IDF}(t)$ 是逆文档频率，用来衡量单词 t 对表达语义所起的重要性，表示为</p>
<script type="math/tex; mode=display">
\operatorname{IDF}(t)=\log \frac{文章总数}{包含单词t的文章总数+1}</script><p>直观的解释是，如果一个单词在非常多的文章里面都出现，那么它可能是一个比较通用的词汇，对于区分某篇文章特殊语义的贡献较小，因此对权重做一定惩罚。</p>
<p>将文章进行单词级别的划分有时候并不是一种好的做法，比如英文中的natural language processing（自然语言处理）一词，如果将natural，language，processing这3个词拆分开来，所表达的含义与三个词连续出现时大相径庭。通常，可以将连续出现的n个词（n≤N）组成的词组（N-gram）也作为一个单独的特征放到向量表示中去，构成N-gram模型。另外，同一个词可能有多种词性变化，却具有相似的含义。在实际应用中，一般会对单词进行词干抽取（Word Stemming）处理，即将不同词性的单词统一成为同一词干的形式。</p>
<ul>
<li>主题模型</li>
</ul>
<p>基于词袋模型或N-gram模型的文本表示模型有一个明显的缺陷，就是无法识别出两个不同的词或词组具有相同的主题。因此，需要一种技术能够将具有相同主题的词或词组映射到同一维度上去，于是产生了主题模型。主题模型是一种特殊的概率图模型。想象一下我们如何判定两个不同的词具有相同的主题呢？这两个词可能有更高的概率同时出现在同一篇文档中；换句话说，给定某一主题，这两个词的产生概率都是比较高的，而另一些不太相关的词汇产生的概率则是较低的。假设有K个主题，我们就把任意文章表示成一个K维的主题向量，其中向量的每一维代表一个主题，权重代表这篇文章属于这个特定主题的概率。主题模型所解决的事情，就是从文本库中发现有代表性的主题（得到每个主题上面词的分布），并且计算出每篇文章对应着哪些主题。</p>
<p>常见的主题模型：pLSA（Probabilistic Latent Semantic Analysis），LDA（Latent Dirichlet Allocation）</p>
<ul>
<li>词嵌入与深度学习模型</li>
</ul>
<p>词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间（通常K=50～300维）上的一个稠密向量（Dense Vector）。K维空间的每一维也可以看作一个隐含的主题，只不过不像主题模型中的主题那样直观。</p>
<p>由于词嵌入将每个词映射成一个K维的向量，如果一篇文档有N个词，就可以用一个N×K维的矩阵来表示这篇文档，但是这样的表示过于底层。在实际应用中，如果仅仅把这个矩阵作为原文本的表示特征输入到机器学习模型中，通常很难得到令人满意的结果。因此，还需要在此基础之上加工出更高层的特征。在传统的浅层机器学习模型中，一个好的特征工程往往可以带来算法效果的显著提升。而深度学习模型正好为我们提供了一种自动地进行特征工程的方式，模型中的每个隐层都可以认为对应着不同抽象层次的特征。从这个角度来讲，深度学习模型能够打败浅层模型也就顺理成章了。卷积神经网络和循环神经网络的结构在文本表示中取得了很好的效果，主要是由于它们能够更好地对文本进行建模，抽取出一些高层的语义特征。与全连接的网络结构相比，卷积神经网络和循环神经网络一方面很好地抓住了文本的特性，另一方面又减少了网络中待学习的参数，提高了训练速度，并且降低了过拟合的风险。</p>
<h2 id="12-Word2Vec原理，与LDA的区别与联系"><a href="#12-Word2Vec原理，与LDA的区别与联系" class="headerlink" title="12 Word2Vec原理，与LDA的区别与联系"></a>12 Word2Vec原理，与LDA的区别与联系</h2><p>Word2Vec是目前最常用的词嵌入模型之一。Word2Vec实际是一种浅层的神经网络模型，它有两种网络结构，分别是CBOW（Continues Bag of Words）和Skip-gram。CBOW的目标是根据上下文出现的词语来预测当前词的生成概率；而Skip-gram是根据当前词来预测上下文中各词的生成概率。</p>
<p>CBOW和Skip-gram都可以表示成由输入层（Input）、映射层（Projection）和输出层（Output）组成的神经网络。输入层中的每个词由独热编码方式表示，即所有词均表示成一个N维向量，其中N为词汇表中单词的总数。在向量中，每个词都将与之对应的维度置为1，其余维度的值均设为0。在映射层（又称隐含层）中，K个隐含单元（Hidden Units）的取值可以由N维输入向量以及连接输入和隐含单元之间的N×K维权重矩阵计算得到。在CBOW中，还需要将各个输入词所计算出的隐含单元求和。</p>
<p>同理，输出层向量的值可以通过隐含层向量（K维），以及连接隐含层和输出层之间的K×N维权重矩阵计算得到。输出层也是一个N维向量，每维与词汇表中的一个单词相对应。最后，对输出层向量应用Softmax激活函数，可以计算出每个单词的生成概率。Softmax激活函数的定义为</p>
<script type="math/tex; mode=display">
P\left(y=w_{n} | x\right)=\frac{\mathrm{e}^{x_{n}}}{\sum_{k=1}^{N} \mathrm{e}^{x_{k}}}</script><p>Word2Vec与LDA的区别和联系：</p>
<ul>
<li>首先，LDA是利用文档中单词的共现关系来对单词按主题聚类，也可以理解为对“文档-单词”矩阵进行分解，得到“文档主题”和“主题-单词”两个概率分布。而Word2Vec其实是对“上下文-单词”矩阵进行学习，其中上下文由周围的几个单词组成，由此得到的词向量表示更多地融入了上下文共现的特征。也就是说，如果两个单词所对应的Word2Vec向量相似度较高，那么它们很可能经常在同样的上下文中出现。</li>
<li>需要说明的是，上述分析的是LDA与Word2Vec的不同，不应该作为主题模型和词嵌入两类方法的主要差异。主题模型通过一定的结构调整可以基于“上下文-单词”矩阵进行主题推理。同样地，词嵌入方法也可以根据“文档-单词”矩阵学习出词的隐含向量表示。</li>
<li>主题模型和词嵌入两类方法最大的不同其实在于模型本身，主题模型是一种基于概率图模型的生成式模型，其似然函数可以写成若干条件概率连乘的形式，其中包括需要推测的隐含变量（即主题）；而词嵌入模型一般表达为神经网络的形式，似然函数定义在网络的输出之上，需要通过学习网络的权重以得到单词的稠密向量表示。</li>
</ul>
<h2 id="13-图像数据不足时的处理方法"><a href="#13-图像数据不足时的处理方法" class="headerlink" title="13 图像数据不足时的处理方法"></a>13 图像数据不足时的处理方法</h2><p>一个模型所能提供的信息一般来源于两个方面，一是训练数据中蕴含的信息；二是在模型的形成过程中（包括构造、学习、推理等），人们提供的先验信息。当训练数据不足时，说明模型从原始数据中获取的信息比较少，这种情况下要想保证模型的效果，就需要更多先验信息。先验信息可以作用在模型上，例如让模型采用特定的内在结构、条件假设或添加其他一些约束条件；先验信息也可以直接施加在数据集上，即根据特定的先验假设去调整、变换或扩展训练数据，让其展现出更多的、更有用的信息，以利于后续模型的训练和学习。</p>
<p>具体到图像分类任务上，训练数据不足带来的问题主要表现在过拟合方面，即模型在训练样本上的效果可能不错，但在测试集上的泛化效果不佳。根据上述讨论，对应的处理方法大致也可以分两类：</p>
<p>一是基于模型的方法，主要是采用降低过拟合风险的措施，包括简化模型（如将非线性模型简化为线性模型）、添加约束项以缩小假设空间（如L1/L2正则项）、集成学习、Dropout超参数等；</p>
<p>二是基于数据的方法，主要通过数据扩充（Data Augmentation），即根据一些先验知识，在保持特定信息的前提下，对原始数据进行适当变换以达到扩充数据集的效果。具体到图像分类任务中，在保持图像类别不变的前提下，可以对训练集中的每幅图像进行以下变换。<br>-（1）一定程度内的随机旋转、平移、缩放、裁剪、填充、左右翻转等，这些变换对应着同一个目标在不同角度的观察结果。</p>
<ul>
<li>（2）对图像中的像素添加噪声扰动，比如椒盐噪声、高斯白噪声等。</li>
<li>（3）颜色变换。例如，在图像的RGB颜色空间上进行主成分分析，得到3个主成分的特征向量及其对应的特征值，然后在每个像素的RGB值上添加方差较小的高斯分布随机数。</li>
<li>（4）改变图像的亮度、清晰度、对比度、锐度等。</li>
</ul>
<p>除了直接在图像空间进行变换，还可以先对图像进行特征提取，然后在图像的特征空间内进行变换，利用一些通用的数据扩充或上采样技术，例如SMOTE（Synthetic Minority Over-sampling Technique）算法。抛开上述这些启发式的变换方法，使用生成模型也可以合成一些新样本，例如当今非常流行的生成式对抗网络模型。</p>
<p>此外，借助已有的其他模型或数据来进行迁移学习在深度学习中也十分常见。例如，对于大部分图像分类任务，并不需要从头开始训练模型，而是借用一个在大规模数据集上预训练好的通用模型，并在针对目标任务的小数据集上进行微调（fine-tune），这种微调操作就可以看成是一种简单的迁移学习。</p>
<h2 id="14-降维"><a href="#14-降维" class="headerlink" title="14 降维"></a>14 降维</h2><p>用一个低维度的向量表示原始高维度的特征显得尤为重要。常见的降维方法有主成分分析、线性判别分析、等距映射、局部线性嵌入、拉普拉斯特征映射、局部保留投影等。</p>
<h2 id="15-主成分分析（PCA）"><a href="#15-主成分分析（PCA）" class="headerlink" title="15 主成分分析（PCA）"></a>15 主成分分析（PCA）</h2><p>PCA是一种线性、非监督、全局的降维算法，旨在找到数据中的主成分，并利用这些主成分表征原始数据，从而达到降维的目的。</p>
<p>工作原理可由两个角度解释，第一个是最大化投影方差（让数据在主轴上投影的方差尽可能大）；第二个是最小化平方误差（样本点到超平面的垂直距离足够近）。</p>
<p>优点</p>
<ul>
<li>计算简单，易于实现 </li>
<li>各主成分之间正交，可消除原始数据成分间的相互影响的因素  </li>
<li>仅仅需要以方差衡量信息量，不受数据集以外的因素影响 </li>
<li>降维维数没有限制，可根据需要制定。</li>
</ul>
<p>缺点</p>
<ul>
<li>无法利用类别的先验信息 </li>
<li>降维后，只与数据有关，主成分各个维度的含义模糊，不易于解释</li>
<li>方差小的非主成分也可能含有对样本差异的重要信息，因降维丢弃可能对后续数据处理有影响 </li>
<li>线性模型，对于复杂数据集难以处理（可用核映射方式改进）。</li>
</ul>
<p>步骤</p>
<ul>
<li>对样本数据进行中心化处理（意义：投影之后均值为0）。</li>
<li>求样本协方差矩阵。</li>
<li>对协方差矩阵进行特征值分解，将特征值从大到小排列。</li>
<li>取特征值前d大对应的特征向量ω1,ω2,…,ωd，将n维样本映射到d维。</li>
</ul>
<p>Note</p>
<ul>
<li>PCA最大方差理论：PCA的目标是最大化投影方差，也就是让数据在主轴上投影的方差最大。PCA旨在找到数据中的主成分，并利用这些主成分表征原始数据，从而达到降维的目的。举一个简单的例子，在三维空间中有一系列数据点，这些点分布在一个过原点的平面上。如果我们用自然坐标系x,y,z三个轴来表示数据，就需要使用三个维度。而实际上，这些点只出现在一个二维平面上，如果我们通过坐标系旋转变换使得数据所在平面与x,y平面重合，那么我们就可以通过x′,y′两个维度表达原始数据，并且没有任何损失，这样就完成了数据的降维。而x′,y′两个轴所包含的信息就是我们要找到的主成分。</li>
</ul>
<h2 id="16-在PCA中有必要做旋转变换"><a href="#16-在PCA中有必要做旋转变换" class="headerlink" title="16 在PCA中有必要做旋转变换"></a>16 在PCA中有必要做旋转变换</h2><p>是的，旋转（正交）是必要的，因为它把由主成分捕获的方差之间的差异最大化，这使得主成分更容易解释。但是我们不要忘记我们做PCA的目的是选择更少的主成分，那些选择的主成分能够解释数据集中最大方差。</p>
<p>通过做旋转，各主成分的相对位置不发生变化，它只能改变点的实际坐标。如果我们没有旋转主成分，PCA的效果会减弱，那样我们不得不选择更多个主成分来解释数据集里的方差。</p>
<h2 id="17-数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗"><a href="#17-数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗" class="headerlink" title="17 数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗"></a>17 数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗</h2><p>需要，因为有相关变量的存在，由特征成分解释的方差被放大。如一个数据集有3个变量，其中有两个是相关的，如果在该数据集上用PCA，第一主成分的方差会是其不相关变量的差异的两倍。此外，加入相关的变量使PCA错误地提高那些变量的重要性，这是有误导的。</p>
<h2 id="18-线性判别分析（LDA）"><a href="#18-线性判别分析（LDA）" class="headerlink" title="18 线性判别分析（LDA）"></a>18 线性判别分析（LDA）</h2><p>LDA是为了让映射后的样本有最好的分类性能。是一种有监督的降维方法，它的中心思想是最大化类间距离和最小化类内距离。目标函数定义为类间距离和类内距离的比值。</p>
<p>步骤：</p>
<ul>
<li>计算数据集中每个类别样本的均值向量 $μ_j$，及总体均值向量 $μ$。</li>
<li>计算类内散度矩阵 $S_w$ ，全局散度矩阵 $S_t$，并得到类间散度矩阵 $S_b = S_t-S_w$。</li>
<li>对矩阵 $S_{w}^{-1} S_{B}$ 进行特征值分解，将特征值从大到小排列。</li>
<li>取特征值前 $d$ 大的对应的特征向量，通过映射将 $n$ 维样本映射到 $d$ 维。</li>
</ul>
<h2 id="19-PCA和LDA的区别"><a href="#19-PCA和LDA的区别" class="headerlink" title="19 PCA和LDA的区别"></a>19 PCA和LDA的区别</h2><p>首先从目标出发，PCA选择的是投影后数据方差最大的方向。由于它是无监督的，因此PCA假设方差越大，信息量越多，用主成分来表示原始数据可以去除冗余的维度，达到降维。而LDA选择的是投影后类内方差小、类间方差大的方向。其用到了类别标签信息，是有监督降维算法，为了找到数据中具有判别性的维度，使得原始数据在这些方向上投影后，不同类别尽可能区分开。</p>
<h2 id="20-连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？"><a href="#20-连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？" class="headerlink" title="20 连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？"></a>20 连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？</h2><p>幅度缩放一般在计算性模型里会用到，离散化一般在线性模型会用到，如LR。</p>
<h2 id="21-离散化的目的："><a href="#21-离散化的目的：" class="headerlink" title="21 离散化的目的："></a>21 离散化的目的：</h2><ul>
<li>非线性。逻辑回归属于广义线性模型，表达能力受限，单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型的表达能力，加大拟合；离散特征的增加和减少都很容易，易于模型的快速迭代。</li>
<li>速度快。稀疏向量内积乘法运算速度快，计算结果方便存储，容易扩展；</li>
<li>鲁棒性。离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄&gt;30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰；</li>
<li>方便交叉与特征组合：离散化后可以进行特征交叉，由 $M+N$ 个变量变为$M*N$个变量，进一步引入非线性，提升表达能力；</li>
<li>稳定性：特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问；</li>
<li>简化模型：特征离散化以后，起到了简化了逻辑回归模型的作用，降低了模型过拟合的风险。</li>
</ul>
<h2 id="22-什么时候分类变量当成连续型变量会更得到一个更好的预测模型"><a href="#22-什么时候分类变量当成连续型变量会更得到一个更好的预测模型" class="headerlink" title="22 什么时候分类变量当成连续型变量会更得到一个更好的预测模型"></a>22 什么时候分类变量当成连续型变量会更得到一个更好的预测模型</h2><p>为了得到更好的预测，只有在分类变量在本质上是有序的情况下才可以被当做连续型变量来处理。</p>
<h2 id="23-缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。"><a href="#23-缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。" class="headerlink" title="23 缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。"></a>23 缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。</h2><p>约有32%的数据不会受到缺失值的影响。</p>
<h2 id="24-是可以捕获连续变量和分类变量之间的相关性"><a href="#24-是可以捕获连续变量和分类变量之间的相关性" class="headerlink" title="24 是可以捕获连续变量和分类变量之间的相关性"></a>24 是可以捕获连续变量和分类变量之间的相关性</h2><p>可以的，我们可以用ANCOVA（协方差分析）技术来捕获连续变量和分类变量之间的相关性。</p>
<h2 id="25-缺失值处理"><a href="#25-缺失值处理" class="headerlink" title="25 缺失值处理"></a>25 缺失值处理</h2><ul>
<li>把缺失值分成单独的一类，这些缺失值说不定会包含一些趋势信息</li>
<li>可以删除他们</li>
<li>我们可以用目标变量来检查他们的分布，如果发现任何模式，我们将保留那些缺失值并给他们一个新的分类，同时删除其他缺失值。</li>
</ul>
<h2 id="26-异常值处理"><a href="#26-异常值处理" class="headerlink" title="26 异常值处理"></a>26 异常值处理</h2><ul>
<li>视为无效信息（噪声点）：结合异常值检测算法，检测出后直接丢弃；</li>
<li>视为有效信息（信号点）：作为缺失值，用缺失值的方式处理；</li>
<li>不处理，直接在具有异常值的数据上进行数据挖掘。</li>
</ul>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="Qiancun Huang WeChat Pay">
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="Qiancun Huang Alipay">
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    Qiancun Huang
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="http://huangqiancun.github.io/2019/06/20/机器学习-特征工程/" title="机器学习-特征工程">http://huangqiancun.github.io/2019/06/20/机器学习-特征工程/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> unless stating additionally.
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/20/机器学习-线性回归&逻辑回归&最大熵/" rel="next" title="机器学习-线性回归&逻辑回归&最大熵">
                <i class="fa fa-chevron-left"></i> 机器学习-线性回归&逻辑回归&最大熵
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/20/深度学习小结/" rel="prev" title="深度学习小结">
                深度学习小结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
	
	
  
  
  
  </article>
  <div>
		
			<div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">------------The End------------</div>
    
</div>
		
	</div>
	
 


    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/photo.jpg" alt="Qiancun Huang">
            
              <p class="site-author-name" itemprop="name">Qiancun Huang</p>
              <p class="site-description motion-element" itemprop="description">A second-year graduate student in Southeast University</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">57</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/huangqiancun?tab=repositories" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto://huangqiancun@foxmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-什么是特征工程"><span class="nav-text">1 什么是特征工程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-数据预处理"><span class="nav-text">2 数据预处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-处理类别型特征"><span class="nav-text">3 处理类别型特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-特征选择的方法"><span class="nav-text">4 特征选择的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-如何进行特征选择"><span class="nav-text">5 如何进行特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-组合特征"><span class="nav-text">6 组合特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-有效地寻找组合特征"><span class="nav-text">7 有效地寻找组合特征</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-标准化和归一化的区别"><span class="nav-text">8 标准化和归一化的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-归一化的作用"><span class="nav-text">9 归一化的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-不需要做归一化的机器学习算法"><span class="nav-text">10 不需要做归一化的机器学习算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-文本表示模型"><span class="nav-text">11 文本表示模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-Word2Vec原理，与LDA的区别与联系"><span class="nav-text">12 Word2Vec原理，与LDA的区别与联系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-图像数据不足时的处理方法"><span class="nav-text">13 图像数据不足时的处理方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14-降维"><span class="nav-text">14 降维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#15-主成分分析（PCA）"><span class="nav-text">15 主成分分析（PCA）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#16-在PCA中有必要做旋转变换"><span class="nav-text">16 在PCA中有必要做旋转变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#17-数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗"><span class="nav-text">17 数据集中部分特征高度相关的，用PCA时需要先去掉相关的变量吗</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#18-线性判别分析（LDA）"><span class="nav-text">18 线性判别分析（LDA）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#19-PCA和LDA的区别"><span class="nav-text">19 PCA和LDA的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20-连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？"><span class="nav-text">20 连续特征，既可以做离散化，也可以做幅度缩放，那这两种处理方式分别适用于什么场景呢？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#21-离散化的目的："><span class="nav-text">21 离散化的目的：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22-什么时候分类变量当成连续型变量会更得到一个更好的预测模型"><span class="nav-text">22 什么时候分类变量当成连续型变量会更得到一个更好的预测模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#23-缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。"><span class="nav-text">23 缺失值分布在离中值有1个标准偏差的范围内，百分之多少的数据不会受到影响。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#24-是可以捕获连续变量和分类变量之间的相关性"><span class="nav-text">24 是可以捕获连续变量和分类变量之间的相关性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#25-缺失值处理"><span class="nav-text">25 缺失值处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#26-异常值处理"><span class="nav-text">26 异常值处理</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        
<div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Qiancun Huang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">483.3k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


</body>
</html>
